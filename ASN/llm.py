"""LLMæ¨¡å—ï¼Œè´Ÿè´£ä¸OpenAI APIé€šä¿¡

è¯¥æ¨¡å—æä¾›äº†ä¸OpenAI APIé€šä¿¡çš„æ¥å£ï¼Œæ‰€æœ‰éœ€è¦ä¸AIæ¨¡å‹äº¤äº’çš„æ¨¡å—éƒ½åº”é€šè¿‡è¯¥æ¨¡å—è¿›è¡Œã€‚
æ¨¡å—ä¼šè¯»å–é…ç½®æ–‡ä»¶ä¸­çš„APIè®¾ç½®ï¼Œå¹¶æä¾›å‘é€è¯·æ±‚å’Œæ¥æ”¶å“åº”çš„åŠŸèƒ½ã€‚
"""

import json
import logging
import os
from typing import Dict, List, Optional, Union, Any

import requests

from ASN.config import get_config, get_llm_config

logger = logging.getLogger(__name__)


class LLMClient:
    """LLMå®¢æˆ·ç«¯ï¼Œè´Ÿè´£ä¸OpenAI APIé€šä¿¡"""

    def __init__(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        self.config = get_llm_config()
        self.debug = self.config.get("debug", False)

        # æ–°å¢è°ƒè¯•æ—¥å¿—éªŒè¯é…ç½®åŠ è½½
        logger.debug("ğŸ” [è°ƒè¯•æ¨¡å¼] LLMé…ç½®å·²åŠ è½½")
        logger.debug(f"å½“å‰è°ƒè¯•æ¨¡å¼çŠ¶æ€: {self.debug}")
        logger.debug(
            f"å®Œæ•´é…ç½®å†…å®¹: {json.dumps(self.config, indent=2, ensure_ascii=False)}"
        )

        # æ·»åŠ ç¼ºå¤±çš„å±æ€§åˆå§‹åŒ–
        self.base_url = self.config.get("base_url", "https://api.openai.com/v1")
        self.api_key = self.config.get("api_key", "")
        self.model = self.config.get("model", "gpt-4")  # æ·»åŠ modelå±æ€§
        self.max_tokens = self.config.get("max_tokens", 4096)
        self.temperature = self.config.get("temperature", 0.0)
        self.api_type = self.config.get("api_type", "openai")
        self.api_version = self.config.get("api_version", None)

        self._validate_config()  # ç¡®ä¿é…ç½®éªŒè¯
        logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")

    def _validate_config(self):
        """éªŒè¯é…ç½®ä¿¡æ¯"""
        if not self.api_key:
            logger.error("APIå¯†é’¥æœªé…ç½®")
            raise ValueError("APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨config.tomlä¸­è®¾ç½®api_key")

        if not self.base_url:
            logger.error("API URLæœªé…ç½®")
            raise ValueError("API URLæœªé…ç½®ï¼Œè¯·åœ¨config.tomlä¸­è®¾ç½®base_url")

    def _prepare_headers(self) -> Dict[str, str]:
        """å‡†å¤‡è¯·æ±‚å¤´

        Returns:
            è¯·æ±‚å¤´å­—å…¸
        """
        headers = {
            "Content-Type": "application/json",
        }

        if self.api_type == "azure":
            headers["api-key"] = self.api_key
            if self.api_version:
                headers["api-version"] = self.api_version
        else:  # openai
            headers["Authorization"] = f"Bearer {self.api_key}"

        return headers

    def send_request(
        self,
        messages: List[Dict[str, str]],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[Union[str, Dict[str, Any]]] = None,
    ) -> Union[Dict[str, Any], Any]:
        """å‘é€è¯·æ±‚åˆ°OpenAI API

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¸©åº¦
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§tokenæ•°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”ï¼Œé»˜è®¤ä¸ºFalse
            tools: å·¥å…·åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNone
            tool_choice: å·¥å…·é€‰æ‹©ï¼Œé»˜è®¤ä¸ºNone

        Returns:
            APIå“åº”å­—å…¸æˆ–æµå¼å“åº”ç”Ÿæˆå™¨
        """
        model = model or self.model
        temperature = temperature if temperature is not None else self.temperature
        max_tokens = max_tokens or self.max_tokens

        # æ„å»ºè¯·æ±‚URL
        url = f"{self.base_url}/chat/completions"
        headers = self._prepare_headers()
        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream,
        }

        # æ·»åŠ å·¥å…·ä¿¡æ¯
        if tools:
            data["tools"] = tools

        if tool_choice:
            data["tool_choice"] = tool_choice

        # å‘é€è¯·æ±‚
        # åœ¨å‘é€è¯·æ±‚å‰æ·»åŠ è°ƒè¯•æ—¥å¿—
        if self.debug:
            logger.debug("â¬†ï¸ å³å°†å‘é€APIè¯·æ±‚:")
            logger.debug(f"URL: {url}")
            logger.debug(f"Headers: {headers}")
            logger.debug(
                f"Request Body: {json.dumps(data, indent=2, ensure_ascii=False)}"
            )

        try:
            headers = self._prepare_headers()

            # å¤„ç†æµå¼å“åº”
            if stream:
                return self._handle_streaming_response(url, headers, data)

            # å¤„ç†æ™®é€šå“åº”
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()

            # è°ƒè¯•æ¨¡å¼ä¸‹è®°å½•å®Œæ•´å“åº”
            if self.debug:
                logger.debug("â¬‡ï¸ æ”¶åˆ°APIå“åº”:")
                # logger.debug(f"Status Code: {response.status_code}")
                # logger.debug(f"Response Body: {response.text}")

                # logger.debug("âœ… [è°ƒè¯•æ¨¡å¼] APIå“åº”è¯¦æƒ…")
                logger.debug(f"Status Code: {response.status_code}")
                logger.debug(f"Response Headers: {dict(response.headers)}")
                logger.debug(f"Full Response: {response.text}")

            return response.json()

        except requests.exceptions.RequestException as e:
            logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
            if hasattr(e, "response") and e.response:
                logger.error(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                logger.error(f"å“åº”å†…å®¹: {e.response.text}")
            raise

    def _handle_streaming_response(
        self, url: str, headers: Dict[str, str], data: Dict[str, Any]
    ):
        # åœ¨æµå¼å¤„ç†ä¸­æ·»åŠ è°ƒè¯•æ—¥å¿—
        if self.debug:
            logger.debug("ğŸ” [è°ƒè¯•æ¨¡å¼] å¼€å§‹å¤„ç†æµå¼å“åº”")  # âœ… æµå¼å¤„ç†æ—¥å¿—

        try:
            with requests.post(
                url, headers=headers, json=data, stream=True
            ) as response:
                if self.debug:
                    logger.debug(f"Streaming Response Status: {response.status_code}")

                for line in response.iter_lines():
                    if not line:
                        continue

                    # ç§»é™¤ "data: " å‰ç¼€
                    if line.startswith(b"data: "):
                        line = line[6:]

                    # è·³è¿‡å¿ƒè·³æ¶ˆæ¯
                    if line.strip() == b"[DONE]":
                        break

                    try:
                        # è§£æJSONå“åº”
                        chunk = json.loads(line)

                        # è§£ææµå¼å“åº”ç‰‡æ®µ
                        yield self._parse_stream_chunk(chunk)
                    except json.JSONDecodeError as e:
                        logger.error(f"è§£ææµå¼å“åº”JSONå¤±è´¥: {e}")
                        logger.error(f"åŸå§‹è¡Œ: {line}")
                        continue
        except requests.exceptions.RequestException as e:
            logger.error(f"æµå¼è¯·æ±‚å¤±è´¥: {e}")
            if hasattr(e, "response") and e.response:
                logger.error(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                logger.error(f"å“åº”å†…å®¹: {e.response.text}")
            raise

    def _parse_stream_chunk(self, chunk: Dict[str, Any]) -> Dict[str, Any]:
        """è§£ææµå¼å“åº”ç‰‡æ®µ

        Args:
            chunk: æµå¼å“åº”ç‰‡æ®µ

        Returns:
            è§£æåçš„æµå¼å“åº”ç‰‡æ®µ
        """
        try:
            choices = chunk.get("choices", [])
            if not choices:
                return {"content": "", "tool_calls": []}

            delta = choices[0].get("delta", {})

            # è§£æå†…å®¹
            content = delta.get("content", "")

            # è§£æå·¥å…·è°ƒç”¨
            tool_calls = delta.get("tool_calls", [])

            # æ„å»ºç»“æœ
            result = {
                "content": content,
                "tool_calls": tool_calls,
                "finish_reason": choices[0].get("finish_reason", None),
            }

            return result
        except Exception as e:
            logger.error(f"è§£ææµå¼å“åº”ç‰‡æ®µå¤±è´¥: {e}")
            logger.error(f"åŸå§‹ç‰‡æ®µ: {chunk}")
            return {"content": "", "tool_calls": []}

    def parse_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æAPIå“åº”

        Args:
            response: APIå“åº”å­—å…¸

        Returns:
            è§£æåçš„å“åº”å­—å…¸ï¼ŒåŒ…å«å†…å®¹å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯
        """
        try:
            # è·å–å“åº”ä¸­çš„é€‰æ‹©
            choices = response.get("choices", [])
            if not choices:
                logger.error("APIå“åº”ä¸­æ²¡æœ‰choiceså­—æ®µ")
                raise ValueError("APIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ²¡æœ‰choiceså­—æ®µ")

            # è·å–ç¬¬ä¸€ä¸ªé€‰æ‹©çš„æ¶ˆæ¯
            message = choices[0].get("message", {})
            if not message:
                logger.error("APIå“åº”ä¸­æ²¡æœ‰messageå­—æ®µ")
                raise ValueError("APIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ²¡æœ‰messageå­—æ®µ")

            # è§£æå†…å®¹
            content = message.get("content", "")

            # è§£æå·¥å…·è°ƒç”¨
            tool_calls = message.get("tool_calls", [])

            # æ„å»ºç»“æœ
            result = {"content": content, "tool_calls": tool_calls}

            return result
        except Exception as e:
            logger.error(f"è§£æAPIå“åº”å¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {response}")
            raise


# åˆ›å»ºå…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹
_llm_client = None


def get_llm_client() -> LLMClient:
    """è·å–LLMå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        LLMå®¢æˆ·ç«¯å®ä¾‹
    """
    global _llm_client

    if _llm_client is None:
        _llm_client = LLMClient()

    return _llm_client


def send_message(
    messages: List[Dict[str, str]],
    model: Optional[str] = None,
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None,
    tools: Optional[List[Dict[str, Any]]] = None,
    tool_choice: Optional[Union[str, Dict[str, Any]]] = None,
) -> Dict[str, Any]:
    """å‘é€æ¶ˆæ¯åˆ°LLM

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¸©åº¦
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§tokenæ•°
        tools: å·¥å…·åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNone
        tool_choice: å·¥å…·é€‰æ‹©ï¼Œé»˜è®¤ä¸ºNone

    Returns:
        è§£æåçš„å“åº”å­—å…¸ï¼ŒåŒ…å«å†…å®¹å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯
    """
    client = get_llm_client()
    response = client.send_request(
        messages=messages,
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        tools=tools,
        tool_choice=tool_choice,
    )

    return client.parse_response(response)


def send_message_stream(
    messages: List[Dict[str, str]],
    model: Optional[str] = None,
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None,
    tools: Optional[List[Dict[str, Any]]] = None,
    tool_choice: Optional[Union[str, Dict[str, Any]]] = None,
):
    """å‘é€æ¶ˆæ¯åˆ°LLMå¹¶è·å–æµå¼å“åº”

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æ¸©åº¦
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§tokenæ•°
        tools: å·¥å…·åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNone
        tool_choice: å·¥å…·é€‰æ‹©ï¼Œé»˜è®¤ä¸ºNone

    Yields:
        æµå¼å“åº”ç‰‡æ®µï¼ŒåŒ…å«å†…å®¹å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯
    """
    client = get_llm_client()
    stream_generator = client.send_request(
        messages=messages,
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
        tools=tools,
        tool_choice=tool_choice,
    )

    for chunk in stream_generator:
        yield chunk

    # ç§»é™¤ä¸éœ€è¦çš„è¿”å›è¯­å¥ï¼Œå› ä¸ºresponseæœªå®šä¹‰
    for chunk in stream_generator:
        yield chunk


def parse_json_response(response: Dict[str, Any]) -> Dict[str, Any]:
    """è§£æJSONæ ¼å¼çš„å“åº”

    Args:
        response: APIå“åº”å­—å…¸

    Returns:
        è§£æåçš„JSONå­—å…¸
    """
    content = response.get("content", "")

    if not content:
        logger.warning("å“åº”å†…å®¹ä¸ºç©º")
        return {}

    # å¢å¼ºçš„é¢„å¤„ç†é€»è¾‘
    try:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰ä»£ç å—
        import re

        json_pattern = re.compile(r"```json(.*?)```", re.DOTALL)
        matches = json_pattern.findall(content)

        if matches:
            # å–æœ€åä¸€ä¸ªåŒ¹é…çš„ä»£ç å—ï¼ˆé˜²æ­¢å¤šæ¬¡å¯¹è¯å¹²æ‰°ï¼‰
            content = matches[-1].strip()
        else:
            # å°è¯•æå–å¯èƒ½çš„JSONéƒ¨åˆ†
            content = content.replace("```json", "").replace("```", "").strip()

        # å¤„ç†æ§åˆ¶å­—ç¬¦
        content = json.dumps(content)[1:-1]  # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦

        # å°è¯•è§£æJSON
        return json.loads(content)
    except json.JSONDecodeError as e:
        logger.error(f"è§£æJSONå¤±è´¥: {e}")
        logger.error(f"é¢„å¤„ç†åçš„å†…å®¹: {content}")

        # äºŒæ¬¡å°è¯•ï¼šæå–ç¬¬ä¸€ä¸ª{å’Œæœ€åä¸€ä¸ª}ä¹‹é—´çš„å†…å®¹
        try:
            start = content.find("{")
            end = content.rfind("}")
            if start != -1 and end != -1 and end > start:
                json_str = content[start : end + 1]
                return json.loads(json_str)
            return {}
        except Exception as e2:
            logger.error(f"äºŒæ¬¡è§£æå¤±è´¥: {e2}")
            return {}
